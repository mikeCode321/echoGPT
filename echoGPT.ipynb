{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6/8JstIQR/DkI7mPgX9yd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### A Model intended to generate text the same likeness as the input text file; hence the 'echo' in 'echoGPT'\n"
      ],
      "metadata": {
        "id": "SVdoTxwzSJgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "sppjaZPfTX1i"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc1FtGRrRWRC",
        "outputId": "fc623eb7-5d7d-4f66-9812-a9bc2f83c73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-07 01:49:01--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-03-07 01:49:01 (78.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "MdJK2HVASdyD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-D6EzXQSkRt",
        "outputId": "03b15e4d-d83f-4c93-e46c-6ad054ca71f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PpdRqnvaSmE7",
        "outputId": "72e88f28-e4e7-4fac-9af1-78c40a85518e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDZQmVwoSsek",
        "outputId": "a3a02d15-ad2e-4faa-89f2-978ac78f65b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "id": "UnsBDNMsSx81"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hello world!$\"))\n",
        "print(decode(encode(\"hello world!$\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvf8XheGS3Wy",
        "outputId": "e8600473-dc20-4308-d169-782c37962f75"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42, 2, 3]\n",
            "hello world!$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "# print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu5o3Q3dS4o1",
        "outputId": "009008f5-349f-4298-cbb6-6b065167b5dc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "6H_3ZcGQTfqU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJfdWbiUjF8",
        "outputId": "9f9ca6a1-ba31-43c4-f5f2-1f341b7723b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE0TbTI7UlYk",
        "outputId": "36883fc0-1790-4ee8-f7e5-948ebd31f406"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfGpyvr6UoQN",
        "outputId": "ab7d6fa4-65c6-4565-8ab6-0ca5fab600e9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATOumt7XWeN2",
        "outputId": "1ff19946-a272-4421-d019-ffd4f1cc8e47"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "zZOiHZ9uZfxw"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_F5YXSVbrAs",
        "outputId": "4a064e81-51e1-4762-dae4-b66441da7873"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4522743225097656\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtpavuyJb0sg",
        "outputId": "0b2a46be-ce79-43f1-9c63-b104ffac897a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DUKIVisun Casshe wisthiot s.\n",
            "LUK:\n",
            "\n",
            "NGOLI io e alllker s?j$NCowens l het hislaspicobar, heay ind, cigigeluandac! thaforo nont\n",
            "SLO:\n",
            "Ange ive nn I ou m,\n",
            "UCENTheanp'Lbet bazzl\n",
            "TEEXNore t b'Thathon:\n",
            "sous min'd ne st wousis s lingilo whee,\n",
            "K:\n",
            "Toow'e's,\n",
            "D:\n",
            "NGLEng, do te! ase may sin ceecate.\n",
            "God? d\n",
            "Aw ht hongur vet ouley, tonches s ousour mes o be angaxHatiminthafe atnt ur whis heand ay out sitourdy spehacugnting akefo tofed werore mo d htreldeg ise se inon ime weagsone the kener bs s oweclishentens t \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(3, 3))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlxThAB5edWb",
        "outputId": "74555e21-80a6-4d1e-fdd4-c407d48d77ae"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a, 1, keepdim=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOzle7FBej0e",
        "outputId": "8bb1edeb-55ed-44b9-c284-347877cab369"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "walUWwI_eAyM",
        "outputId": "0565a5f2-2b86-45b9-fe90-dddd859f297f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randint(0,10,(3,2)).float()\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU8LG0X7fLZY",
        "outputId": "51ee28ca-1d2e-4e92-9c9b-67f151a92654"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7., 6.],\n",
              "        [9., 6.],\n",
              "        [3., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1.0000, 0.0000, 0.0000] *\n",
        "                          [7]\n",
        "                          [9]\n",
        "                          [3] = [1 * 7 + 0 * 9 + 0 * 3] = [7]\n",
        "\n",
        "[1.0000, 0.0000, 0.0000] *\n",
        "                      [6]\n",
        "                      [6]\n",
        "                      [1] = [1 * 6 + 0 * 6 + 0 * 1] = [6]\n",
        "\n",
        "[0.5000, 0.5000, 0.0000]* [7]\n",
        "                          [9]\n",
        "                          [3] = [0.5 * 7 + 0.5 * 9 + 0 * 3] = [8]\n",
        "\n",
        "[0.5000, 0.5000, 0.0000] *\n",
        "                      [6]\n",
        "                      [6]\n",
        "                      [3] = [0.5 * 6 + 0.5 * 6 + 0 * 3] = [3+3+0] = [6]\n"
      ],
      "metadata": {
        "id": "EpFdFGX4fS15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = a @ b\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZzQkEDfPLa",
        "outputId": "e1458d13-56fa-43f8-b84d-d9cc8be3ad00"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[7.0000, 6.0000],\n",
              "        [8.0000, 6.0000],\n",
              "        [6.3333, 4.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mjKCqZ0cV4P",
        "outputId": "52026134-54c1-4db1-a0c8-b28009582866"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpmEfgz8dw9f",
        "outputId": "b13730f1-6107-45b9-e97f-5ad1a4e634a6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvDIXpbFjx6b",
        "outputId": "12aa68b0-836e-489a-dd47-56ccbdf854a8"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [ 0.1808, -0.0700],\n",
        "# [-0.3596, -0.9152],\n",
        "# whats being done in the for loop cell below (manual here)\n",
        "print(((0.1808 + -0.3596 )) / 2)\n",
        "print(((-0.0700 + -0.9152 )) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g08Xb5LCj6TV",
        "outputId": "21667c9b-d767-49e3-f60e-e2405edca17b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0894\n",
            "-0.49260000000000004\n",
            "-0.291\n",
            "-0.5820000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "sLfQgjwOm04v"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhDpUWRhmFN",
        "outputId": "d5481ab4-da0f-43bd-9454-1227ba8b0f73"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xYAqskdhnD7",
        "outputId": "eb4fc40f-bfac-4ea0-e2f0-da21f00fb6a9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkHZTzg3h0lZ",
        "outputId": "5dd7b7d7-ba72-4c09-be84-59026a04f5d3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpdYq2wch2HQ",
        "outputId": "513af151-a220-4f0b-8ecc-1d32d9d5e3f7"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self attention via softmax normalization"
      ],
      "metadata": {
        "id": "8r1Iz0MhjWua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy9EWuUch5BZ",
        "outputId": "fa344b3c-8e79-4f99-8ac6-885d04c05a10"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.zeros((T,T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE0ZYZYxiKxQ",
        "outputId": "277a8b1c-cb39-4d73-9558-edf41dceb8c5"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei.masked_fill(tril == 0, float('-inf'))"
      ],
      "metadata": {
        "id": "KBMiZaiPjMpy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = F.softmax(wei, dim=-1)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgeL2oXijNzd",
        "outputId": "86befb05-d7f3-43a0-e985-7b712eb4a47c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow3 = wei @ x\n",
        "xbow3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKAnBF_SjPSY",
        "outputId": "5e9232ca-886e-4f34-a6a9-3249f3e74a1d"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 4: self-attention!\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "print('B =', B)\n",
        "print('T =', T)\n",
        "print('C =', C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro6sFseujQoD",
        "outputId": "6c4730de-142f-42b5-f308-dabf78c03eaa"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B = 4\n",
            "T = 8\n",
            "C = 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(B,T,C)\n",
        "x[:2, :, :5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6GbpKp4vKfw",
        "outputId": "dc1a9878-16fc-4f7f-e09b-69add1ab8150"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258],\n",
              "         [-0.6631, -0.2513,  1.0101,  0.1215,  0.1584],\n",
              "         [-0.8345,  0.5978, -0.0514, -0.0646, -0.4970],\n",
              "         [-1.6669, -1.3651, -0.1655,  0.9623,  0.0315],\n",
              "         [-2.0555,  1.8275,  1.3035, -0.4501,  1.3471],\n",
              "         [-0.8961,  0.0662, -0.0563,  2.3412, -2.7234],\n",
              "         [ 0.1910, -0.3425,  1.7955,  1.3915,  1.0785],\n",
              "         [-0.5819, -0.2208,  0.0135, -0.3057, -0.0304]],\n",
              "\n",
              "        [[ 0.4562, -1.0917, -0.8207,  1.8634,  0.8148],\n",
              "         [ 0.0210,  1.0060, -1.2492,  0.2441, -0.6387],\n",
              "         [ 2.2007, -0.2195,  0.5427,  2.5867, -0.4687],\n",
              "         [ 0.2922,  1.3143,  1.2607, -0.3505, -2.0660],\n",
              "         [ 0.1275, -0.0560,  0.8315, -0.5512,  1.0477],\n",
              "         [ 0.3091,  1.1661, -2.1821, -1.0422,  1.0207],\n",
              "         [ 0.0943, -0.3156,  0.7850, -0.8699, -1.6525],\n",
              "         [ 0.6455, -0.3313, -1.0390,  0.9112,  1.2984]]])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)"
      ],
      "metadata": {
        "id": "HbzrB4dguxZh"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = key(x)   # (B, T, 16)\n",
        "k[:2,:,:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss5NOZFPu7k-",
        "outputId": "ad8872f9-5777-497e-9ae6-c3adb3819a27"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-6.5674e-01,  2.8302e-02,  9.4470e-03, -6.9949e-01, -3.6043e-01],\n",
              "         [-3.9319e-01,  8.2196e-01, -7.0274e-01,  9.5429e-02, -1.2218e-01],\n",
              "         [ 2.1567e-01, -3.5065e-01,  2.1671e-03,  4.2317e-01, -2.2844e-01],\n",
              "         [ 8.9999e-01, -1.2723e-01,  5.4581e-01,  4.2544e-01, -4.5128e-01],\n",
              "         [ 3.3199e-02,  5.8858e-01, -4.4368e-01,  3.7748e-01, -6.8257e-01],\n",
              "         [ 2.0985e-01,  4.3915e-02, -7.0198e-02,  7.2701e-02, -2.0124e-01],\n",
              "         [ 6.1001e-01, -3.2841e-01, -8.5571e-01,  8.5427e-01,  7.8055e-01],\n",
              "         [ 1.4591e-01,  1.3493e-01, -2.3353e-01, -4.1732e-02,  2.9277e-01]],\n",
              "\n",
              "        [[ 1.1104e+00, -8.7192e-01,  7.0978e-01,  3.6331e-01,  2.0670e-01],\n",
              "         [ 3.2561e-01,  5.7866e-01,  5.4575e-01, -7.2274e-01,  1.2343e+00],\n",
              "         [-1.5634e-02, -5.4639e-01,  3.0958e-01,  3.5532e-01,  5.9885e-01],\n",
              "         [-2.4959e-01,  2.7492e-01,  2.6894e-01, -3.6563e-01, -3.2585e-01],\n",
              "         [ 3.9181e-01,  5.7756e-01,  1.3630e-01, -3.3129e-01,  3.4955e-01],\n",
              "         [ 6.6613e-01,  2.1817e+00, -4.7026e-01,  5.5768e-02, -8.0701e-01],\n",
              "         [-5.6865e-01,  4.0198e-01, -5.5940e-01,  2.4041e-01,  2.5784e-02],\n",
              "         [ 5.9567e-01,  2.7697e-01, -5.3694e-01,  3.8806e-01, -5.2068e-01]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = query(x) # (B, T, 16)\n",
        "q[:1, :1, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33VcOUV5vERp",
        "outputId": "809b7802-6f05-4176-cef9-dd22603f5307"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007,\n",
              "          -0.5239, -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,\n",
              "           0.2862,  0.5710]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[:1, :1 , :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgvOppPExFpy",
        "outputId": "3a913df4-c490-4e7f-fe50-a1c92090b9d3"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6567,  0.0283,  0.0094, -0.6995, -0.3604,  0.8376, -0.4446,\n",
              "           0.1228,  0.6276, -0.6222,  0.3483,  0.2411,  0.5409, -0.2605,\n",
              "           0.3612, -0.0436]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[:1, :1 , :].transpose(-2,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dveP0VsAw8HK",
        "outputId": "d4eda3c8-2b2d-4e00-ff98-e108e4d26f2f"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6567],\n",
              "         [ 0.0283],\n",
              "         [ 0.0094],\n",
              "         [-0.6995],\n",
              "         [-0.3604],\n",
              "         [ 0.8376],\n",
              "         [-0.4446],\n",
              "         [ 0.1228],\n",
              "         [ 0.6276],\n",
              "         [-0.6222],\n",
              "         [ 0.3483],\n",
              "         [ 0.2411],\n",
              "         [ 0.5409],\n",
              "         [-0.2605],\n",
              "         [ 0.3612],\n",
              "         [-0.0436]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "wei[:2,:,:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdNW0DVDv3yr",
        "outputId": "3febd1c5-328a-4a3e-fb71-2650192b87de"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 4.3221e-01, -3.4657e-01, -1.4631e+00,  3.2895e-02,  8.7217e-01],\n",
              "         [-1.2225e+00,  4.2318e-02,  1.6674e+00,  4.7402e-01, -3.9212e-01],\n",
              "         [-9.0737e-01, -2.5469e+00,  1.4997e+00, -6.8395e-01,  2.7916e-01],\n",
              "         [-1.4066e+00,  3.1887e-01,  9.5003e-01, -4.7187e-01,  6.4279e-01],\n",
              "         [-3.2678e-01, -3.8157e+00, -3.3920e-01,  7.4762e-01,  6.4912e-01],\n",
              "         [ 8.7737e-01,  2.1680e+00, -2.4931e-01, -1.4231e+00,  1.4555e-01],\n",
              "         [-2.3583e-02,  9.0819e-01,  8.2675e-01, -8.6153e-01,  3.3840e-02],\n",
              "         [ 7.6655e-01,  1.1162e+00,  2.3495e+00, -5.3060e-01, -2.1206e+00]],\n",
              "\n",
              "        [[-1.7818e+00,  2.5224e+00, -1.5429e+00, -1.2020e-01,  2.3735e+00],\n",
              "         [ 1.0509e-01, -1.1810e+00,  8.5433e-01,  1.5353e-01, -1.5560e+00],\n",
              "         [-1.1781e+00,  1.1836e+00,  1.8008e-01,  9.7110e-01,  4.9608e-02],\n",
              "         [ 2.7031e-01,  7.3144e-01, -5.9977e-01,  5.1165e-01,  9.2963e-01],\n",
              "         [ 5.1286e-01, -6.3709e-01, -2.2027e-01,  7.8781e-01,  6.5718e-01],\n",
              "         [ 2.1955e+00, -1.4789e+00,  4.7009e-01, -1.2690e-01,  2.8637e-01],\n",
              "         [-1.3270e+00,  1.4166e+00,  2.6224e-01,  8.3103e-01,  1.1933e+00],\n",
              "         [ 1.3166e+00, -3.2134e-01,  1.1748e-04, -4.7204e-01,  4.6756e-01]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyf6AuUawF3e",
        "outputId": "3b65610f-201d-4719-f8ab-e82705a87a31"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei[:1, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ObOWOKNzoo0",
        "outputId": "de943f46-750b-4d76-bf5f-e16f1a28e380"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.3636, 0.6364, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2375, 0.2224, 0.5401, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2013, 0.2543, 0.3267, 0.2177, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.1848, 0.1627, 0.1845, 0.2382, 0.2297, 0.0000, 0.0000, 0.0000],\n",
              "         [0.1624, 0.2488, 0.1456, 0.1404, 0.1494, 0.1533, 0.0000, 0.0000],\n",
              "         [0.1355, 0.1562, 0.1534, 0.1286, 0.1363, 0.1485, 0.1415, 0.0000],\n",
              "         [0.1204, 0.1254, 0.1756, 0.1121, 0.1098, 0.1186, 0.1185, 0.1196]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = value(x)\n",
        "v[:1, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDf4zM4QzsLN",
        "outputId": "a3800c3e-55ae-439b-ef53-a6c5ee2d167c"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8604, -0.6466,  0.0754, -0.6363, -0.1464,  0.3840, -0.3053,\n",
              "          -0.6389,  0.0544,  0.0762,  0.2364, -0.1792, -0.2908,  0.3348,\n",
              "          -0.9431, -0.1245],\n",
              "         [-0.8963, -0.1909,  0.0988, -1.0337, -0.4137,  0.9316, -0.1586,\n",
              "          -0.1791,  0.1190,  0.6819,  0.0265,  0.5562, -0.1615,  0.1101,\n",
              "           0.0846, -0.6664],\n",
              "         [-0.7785,  0.2959, -0.2016, -0.7096,  0.4515,  0.4565,  0.2554,\n",
              "           0.4989,  0.0964,  0.5159,  0.3097, -0.3569, -0.2772, -0.3573,\n",
              "           0.4011,  0.0285],\n",
              "         [ 0.6401, -0.1027,  0.4378,  0.6083,  0.5365,  0.3228,  0.0042,\n",
              "           0.6595,  0.4381, -0.3499, -1.4774, -0.4494,  0.6942, -0.0524,\n",
              "           0.1576,  0.2287],\n",
              "         [ 0.3436,  0.7927,  1.3172,  0.2551, -0.1853,  0.3615,  1.2092,\n",
              "           0.6290,  0.1703,  0.3958,  0.2562, -0.1899, -0.8195,  0.0613,\n",
              "           0.2854, -1.2319],\n",
              "         [ 1.6714, -0.7109,  1.5069,  2.0694,  0.4068,  0.2825,  0.9223,\n",
              "           1.3963, -1.0078,  0.0742,  0.2363,  0.8289,  0.1465, -1.5054,\n",
              "           0.6776,  0.4237],\n",
              "         [-0.1874,  0.7068,  0.2935,  0.0629,  0.1211, -0.4967, -0.0377,\n",
              "          -0.4351, -0.4190,  0.2541,  0.3437,  1.0836, -0.4296,  0.1457,\n",
              "           0.9732,  0.8517],\n",
              "         [-0.2440,  0.7098,  0.6626, -0.4403, -0.1935,  0.6630,  0.1910,\n",
              "          -0.4679,  0.3835,  0.2616, -0.0362, -0.2773, -0.8855,  0.3346,\n",
              "           0.0258,  0.0223]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = wei @ v\n",
        "print(wei.shape)\n",
        "print(v.shape)\n",
        "out[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKnpINiP0EZt",
        "outputId": "a2e63585-35ce-4cfa-abaf-50670bb1d1fd"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 8])\n",
            "torch.Size([4, 8, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.8604, -0.6466,  0.0754, -0.6363, -0.1464,  0.3840, -0.3053,\n",
              "          -0.6389,  0.0544,  0.0762,  0.2364, -0.1792, -0.2908,  0.3348,\n",
              "          -0.9431, -0.1245],\n",
              "         [-0.8832, -0.3566,  0.0903, -0.8892, -0.3165,  0.7325, -0.2120,\n",
              "          -0.3463,  0.0955,  0.4617,  0.1028,  0.2888, -0.2085,  0.1918,\n",
              "          -0.2891, -0.4693],\n",
              "         [-0.8242, -0.0362, -0.0690, -0.7643,  0.1171,  0.5450,  0.0301,\n",
              "           0.0779,  0.0914,  0.4484,  0.2293, -0.1116, -0.2547, -0.0890,\n",
              "           0.0115, -0.1624],\n",
              "         [-0.5162, -0.1044,  0.0697, -0.4904,  0.1296,  0.5337, -0.0174,\n",
              "           0.1324,  0.1681,  0.2812, -0.1661, -0.1090, -0.0391, -0.0328,\n",
              "          -0.0029, -0.1355],\n",
              "         [-0.2171,  0.0617,  0.3997, -0.2132,  0.0742,  0.4667,  0.2437,\n",
              "           0.2464,  0.1907,  0.2278, -0.1879, -0.1592, -0.1541,  0.0155,\n",
              "           0.0166, -0.3547],\n",
              "         [-0.0786, -0.1145,  0.4968, -0.0231,  0.0491,  0.5033,  0.2708,\n",
              "           0.3250, -0.0151,  0.2785, -0.0429,  0.0929, -0.1302, -0.1993,\n",
              "           0.0949, -0.2688],\n",
              "         [-0.0252,  0.0172,  0.4958,  0.0726,  0.1061,  0.3301,  0.2700,\n",
              "           0.2783, -0.0887,  0.2519,  0.0123,  0.2006, -0.1686, -0.1936,\n",
              "           0.2444, -0.0717],\n",
              "         [-0.0964,  0.1101,  0.4725, -0.0345,  0.0890,  0.3731,  0.2492,\n",
              "           0.1893, -0.0171,  0.2597,  0.0131,  0.1078, -0.2555, -0.1290,\n",
              "           0.2153, -0.0493]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9r283x1i0KpA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}