{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzKCRdMV1px1uuRG2H+t8S"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### A Model intended to generate text the same likeness as the input text file; hence the 'echo' in 'echoGPT'\n"
      ],
      "metadata": {
        "id": "SVdoTxwzSJgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "sppjaZPfTX1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bc1FtGRrRWRC",
        "outputId": "10b2f6de-2145-46c4-b47c-e034ce3c8022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-07 18:05:57--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.007s  \n",
            "\n",
            "2025-03-07 18:05:58 (157 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "MdJK2HVASdyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-D6EzXQSkRt",
        "outputId": "9a097c02-845e-40e7-ce7a-c44902b0e1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PpdRqnvaSmE7",
        "outputId": "04966268-942f-4455-e6d2-7cfba7a909c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "print(''.join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDZQmVwoSsek",
        "outputId": "ed5bef8b-9631-46fa-ad91-bd1d3ff954c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }"
      ],
      "metadata": {
        "id": "UnsBDNMsSx81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hello world!$\"))\n",
        "print(decode(encode(\"hello world!$\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvf8XheGS3Wy",
        "outputId": "21808bfb-ae1e-4c0d-85d8-aac6163f0fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 43, 50, 50, 53, 1, 61, 53, 56, 50, 42, 2, 3]\n",
            "hello world!$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "# print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu5o3Q3dS4o1",
        "outputId": "497d4a44-2579-4dc7-c6bf-8d88dabe1872"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "6H_3ZcGQTfqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaJfdWbiUjF8",
        "outputId": "9b8bc706-850c-415b-e29d-0ff31e23e90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vE0TbTI7UlYk",
        "outputId": "34cc183c-f954-4538-8f68-f2a724f3462f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([18]) the target: 47\n",
            "when input is tensor([18, 47]) the target: 56\n",
            "when input is tensor([18, 47, 56]) the target: 57\n",
            "when input is tensor([18, 47, 56, 57]) the target: 58\n",
            "when input is tensor([18, 47, 56, 57, 58]) the target: 1\n",
            "when input is tensor([18, 47, 56, 57, 58,  1]) the target: 15\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15]) the target: 47\n",
            "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "xb, yb = get_batch('train')\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfGpyvr6UoQN",
        "outputId": "ba8f6880-7fb0-473d-b805-65ee44132658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([4, 8])\n",
            "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
            "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
            "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
            "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
            "targets:\n",
            "torch.Size([4, 8])\n",
            "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
            "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
            "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
            "        [17, 27, 10,  0, 21,  1, 54, 39]])\n",
            "----\n",
            "when input is [24] the target: 43\n",
            "when input is [24, 43] the target: 58\n",
            "when input is [24, 43, 58] the target: 5\n",
            "when input is [24, 43, 58, 5] the target: 57\n",
            "when input is [24, 43, 58, 5, 57] the target: 1\n",
            "when input is [24, 43, 58, 5, 57, 1] the target: 46\n",
            "when input is [24, 43, 58, 5, 57, 1, 46] the target: 43\n",
            "when input is [24, 43, 58, 5, 57, 1, 46, 43] the target: 39\n",
            "when input is [44] the target: 53\n",
            "when input is [44, 53] the target: 56\n",
            "when input is [44, 53, 56] the target: 1\n",
            "when input is [44, 53, 56, 1] the target: 58\n",
            "when input is [44, 53, 56, 1, 58] the target: 46\n",
            "when input is [44, 53, 56, 1, 58, 46] the target: 39\n",
            "when input is [44, 53, 56, 1, 58, 46, 39] the target: 58\n",
            "when input is [44, 53, 56, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52] the target: 58\n",
            "when input is [52, 58] the target: 1\n",
            "when input is [52, 58, 1] the target: 58\n",
            "when input is [52, 58, 1, 58] the target: 46\n",
            "when input is [52, 58, 1, 58, 46] the target: 39\n",
            "when input is [52, 58, 1, 58, 46, 39] the target: 58\n",
            "when input is [52, 58, 1, 58, 46, 39, 58] the target: 1\n",
            "when input is [52, 58, 1, 58, 46, 39, 58, 1] the target: 46\n",
            "when input is [25] the target: 17\n",
            "when input is [25, 17] the target: 27\n",
            "when input is [25, 17, 27] the target: 10\n",
            "when input is [25, 17, 27, 10] the target: 0\n",
            "when input is [25, 17, 27, 10, 0] the target: 21\n",
            "when input is [25, 17, 27, 10, 0, 21] the target: 1\n",
            "when input is [25, 17, 27, 10, 0, 21, 1] the target: 54\n",
            "when input is [25, 17, 27, 10, 0, 21, 1, 54] the target: 39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "\n",
        "            logits, loss = self(idx)\n",
        "\n",
        "            logits = logits[:, -1, :]\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n",
        "\n",
        "m = BigramLanguageModel(vocab_size)\n",
        "logits, loss = m(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)\n",
        "\n",
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATOumt7XWeN2",
        "outputId": "2599e099-b2d0-4b1f-a9af-3c8f110ea6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8786, grad_fn=<NllLossBackward0>)\n",
            "\n",
            "Sr?qP-QWktXoL&jLDJgOLVz'RIoDqHdhsV&vLLxatjscMpwLERSPyao.qfzs$Ys$zF-w,;eEkzxjgCKFChs!iWW.ObzDnxA Ms$3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a PyTorch optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "zZOiHZ9uZfxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "for steps in range(10000): # increase number of steps for good results...\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(loss.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_F5YXSVbrAs",
        "outputId": "88a48066-5583-4451-ccf7-0f132354c6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5727508068084717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtpavuyJb0sg",
        "outputId": "fcb6bd44-e3f5-46bd-fbb1-d14058bf603e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iyoteng h hasbe pave pirance\n",
            "Rie hicomyonthar's\n",
            "Plinseard ith henoure wounonthioneir thondy, y heltieiengerofo'dsssit ey\n",
            "KIN d pe wither vouprrouthercc.\n",
            "hathe; d!\n",
            "My hind tt hinig t ouchos tes; st yo hind wotte grotonear 'so it t jod weancotha:\n",
            "h hay.JUCle n prids, r loncave w hollular s O:\n",
            "HIs; ht anjx?\n",
            "\n",
            "DUThinqunt.\n",
            "\n",
            "LaZAnde.\n",
            "athave l.\n",
            "KEONH:\n",
            "ARThanco be y,-hedarwnoddy scace, tridesar, wnl'shenous s ls, theresseys\n",
            "PlorseelapinghiybHen yof GLUCEN t l-t E:\n",
            "I hisgothers je are!-e!\n",
            "QLYotouciullle'z\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tril(torch.ones(3, 3))\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlxThAB5edWb",
        "outputId": "1404707f-a332-4f08-d6ae-4a9899a72129"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0.],\n",
              "        [1., 1., 0.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(a, 1, keepdim=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOzle7FBej0e",
        "outputId": "85d0679e-3ab5-42d1-afda-393ee8b3eb1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "walUWwI_eAyM",
        "outputId": "e5b910a1-f734-4b0e-8cad-40f4c86c00ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randint(0,10,(3,2)).float()\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BU8LG0X7fLZY",
        "outputId": "694a4ac0-8ee1-4ed2-a815-75e08a006710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2.],\n",
              "        [0., 9.],\n",
              "        [3., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1.0000, 0.0000, 0.0000] *\n",
        "                          [7]\n",
        "                          [9]\n",
        "                          [3] = [1 * 7 + 0 * 9 + 0 * 3] = [7]\n",
        "\n",
        "[1.0000, 0.0000, 0.0000] *\n",
        "                      [6]\n",
        "                      [6]\n",
        "                      [1] = [1 * 6 + 0 * 6 + 0 * 1] = [6]\n",
        "\n",
        "[0.5000, 0.5000, 0.0000]* [7]\n",
        "                          [9]\n",
        "                          [3] = [0.5 * 7 + 0.5 * 9 + 0 * 3] = [8]\n",
        "\n",
        "[0.5000, 0.5000, 0.0000] *\n",
        "                      [6]\n",
        "                      [6]\n",
        "                      [3] = [0.5 * 6 + 0.5 * 6 + 0 * 3] = [3+3+0] = [6]\n"
      ],
      "metadata": {
        "id": "EpFdFGX4fS15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = a @ b\n",
        "c"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9ZzQkEDfPLa",
        "outputId": "069153ab-7e50-4165-fd7e-20c687e3dced"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0000, 2.0000],\n",
              "        [1.0000, 5.5000],\n",
              "        [1.6667, 3.6667]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# toy example illustrating how matrix multiplication can be used for a \"weighted aggregation\"\n",
        "torch.manual_seed(42)\n",
        "a = torch.tril(torch.ones(3, 3))\n",
        "a = a / torch.sum(a, 1, keepdim=True)\n",
        "b = torch.randint(0,10,(3,2)).float()\n",
        "c = a @ b\n",
        "print('a=')\n",
        "print(a)\n",
        "print('--')\n",
        "print('b=')\n",
        "print(b)\n",
        "print('--')\n",
        "print('c=')\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mjKCqZ0cV4P",
        "outputId": "be8e4616-47ae-441d-8e5b-10f886c478c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a=\n",
            "tensor([[1.0000, 0.0000, 0.0000],\n",
            "        [0.5000, 0.5000, 0.0000],\n",
            "        [0.3333, 0.3333, 0.3333]])\n",
            "--\n",
            "b=\n",
            "tensor([[2., 7.],\n",
            "        [6., 4.],\n",
            "        [6., 5.]])\n",
            "--\n",
            "c=\n",
            "tensor([[2.0000, 7.0000],\n",
            "        [4.0000, 5.5000],\n",
            "        [4.6667, 5.3333]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,2 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpmEfgz8dw9f",
        "outputId": "0e531f7c-9fec-404e-cf65-98e4358437b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvDIXpbFjx6b",
        "outputId": "12807732-f993-4935-e7c7-3fb933de248d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.3596, -0.9152],\n",
              "        [ 0.6258,  0.0255],\n",
              "        [ 0.9545,  0.0643],\n",
              "        [ 0.3612,  1.1679],\n",
              "        [-1.3499, -0.5102],\n",
              "        [ 0.2360, -0.2398],\n",
              "        [-0.9211,  1.5433]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [ 0.1808, -0.0700],\n",
        "# [-0.3596, -0.9152],\n",
        "# whats being done in the for loop cell below (manual here)\n",
        "print(((0.1808 + -0.3596 )) / 2)\n",
        "print(((-0.0700 + -0.9152 )) / 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g08Xb5LCj6TV",
        "outputId": "427679c7-7bb6-4431-a5d7-6a92cadb9413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.0894\n",
            "-0.49260000000000004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B,T,C))\n",
        "for b in range(B):\n",
        "    for t in range(T):\n",
        "        xprev = x[b,:t+1] # (t,C)\n",
        "        xbow[b,t] = torch.mean(xprev, 0)"
      ],
      "metadata": {
        "id": "sLfQgjwOm04v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xhDpUWRhmFN",
        "outputId": "fa82b14e-9381-4e0c-be8d-a804b5af11d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# version 2: using matrix multiply for a weighted aggregation\n",
        "wei = torch.tril(torch.ones(T, T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7xYAqskdhnD7",
        "outputId": "e38c50b0-6022-4204-e335-f1bded8db442"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei / wei.sum(1, keepdim=True)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkHZTzg3h0lZ",
        "outputId": "3ac35a88-0297-43dd-b94e-4e8e9f0618be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2 = wei @ x # (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
        "xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpdYq2wch2HQ",
        "outputId": "17d032e8-42be-4a52-c6c8-73ec67122fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1808, -0.0700],\n",
              "        [-0.0894, -0.4926],\n",
              "        [ 0.1490, -0.3199],\n",
              "        [ 0.3504, -0.2238],\n",
              "        [ 0.3525,  0.0545],\n",
              "        [ 0.0688, -0.0396],\n",
              "        [ 0.0927, -0.0682],\n",
              "        [-0.0341,  0.1332]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self attention via softmax normalization"
      ],
      "metadata": {
        "id": "8r1Iz0MhjWua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy9EWuUch5BZ",
        "outputId": "bb454bc9-5f05-4b3b-cfcf-3c3750846b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = torch.zeros((T,T))\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE0ZYZYxiKxQ",
        "outputId": "370d883a-3714-4df0-df2c-4c82584eaac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei.masked_fill(tril == 0, float('-inf'))"
      ],
      "metadata": {
        "id": "KBMiZaiPjMpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wei = F.softmax(wei, dim=-1)\n",
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgeL2oXijNzd",
        "outputId": "19a3539a-407f-4cda-ef3b-22a22da4bb67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow3 = wei @ x\n",
        "xbow3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKAnBF_SjPSY",
        "outputId": "11589baa-d0b8-41d4-8396-f53eda713c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700],\n",
              "         [-0.0894, -0.4926],\n",
              "         [ 0.1490, -0.3199],\n",
              "         [ 0.3504, -0.2238],\n",
              "         [ 0.3525,  0.0545],\n",
              "         [ 0.0688, -0.0396],\n",
              "         [ 0.0927, -0.0682],\n",
              "         [-0.0341,  0.1332]],\n",
              "\n",
              "        [[ 1.3488, -0.1396],\n",
              "         [ 0.8173,  0.4127],\n",
              "         [-0.1342,  0.4395],\n",
              "         [ 0.2711,  0.4774],\n",
              "         [ 0.2421,  0.0694],\n",
              "         [ 0.0084,  0.0020],\n",
              "         [ 0.0712, -0.1128],\n",
              "         [ 0.2527,  0.2149]],\n",
              "\n",
              "        [[-0.6631, -0.2513],\n",
              "         [ 0.1735, -0.0649],\n",
              "         [ 0.1685,  0.3348],\n",
              "         [-0.1621,  0.1765],\n",
              "         [-0.2312, -0.0436],\n",
              "         [-0.1015, -0.2855],\n",
              "         [-0.2593, -0.1630],\n",
              "         [-0.3015, -0.2293]],\n",
              "\n",
              "        [[ 1.6455, -0.8030],\n",
              "         [ 1.4985, -0.5395],\n",
              "         [ 0.4954,  0.3420],\n",
              "         [ 1.0623, -0.1802],\n",
              "         [ 1.1401, -0.4462],\n",
              "         [ 1.0870, -0.4071],\n",
              "         [ 1.0430, -0.1299],\n",
              "         [ 1.1138, -0.1641]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "print('B =', B)\n",
        "print('T =', T)\n",
        "print('C =', C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ro6sFseujQoD",
        "outputId": "f914657d-beae-475e-fc2d-3d17d0c0672d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B = 4\n",
            "T = 8\n",
            "C = 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(B,T,C)\n",
        "x[:2, :, :5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6GbpKp4vKfw",
        "outputId": "f34304be-9e5d-4a7f-ca12-556ced3c028b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1808, -0.0700, -0.3596, -0.9152,  0.6258],\n",
              "         [-0.6631, -0.2513,  1.0101,  0.1215,  0.1584],\n",
              "         [-0.8345,  0.5978, -0.0514, -0.0646, -0.4970],\n",
              "         [-1.6669, -1.3651, -0.1655,  0.9623,  0.0315],\n",
              "         [-2.0555,  1.8275,  1.3035, -0.4501,  1.3471],\n",
              "         [-0.8961,  0.0662, -0.0563,  2.3412, -2.7234],\n",
              "         [ 0.1910, -0.3425,  1.7955,  1.3915,  1.0785],\n",
              "         [-0.5819, -0.2208,  0.0135, -0.3057, -0.0304]],\n",
              "\n",
              "        [[ 0.4562, -1.0917, -0.8207,  1.8634,  0.8148],\n",
              "         [ 0.0210,  1.0060, -1.2492,  0.2441, -0.6387],\n",
              "         [ 2.2007, -0.2195,  0.5427,  2.5867, -0.4687],\n",
              "         [ 0.2922,  1.3143,  1.2607, -0.3505, -2.0660],\n",
              "         [ 0.1275, -0.0560,  0.8315, -0.5512,  1.0477],\n",
              "         [ 0.3091,  1.1661, -2.1821, -1.0422,  1.0207],\n",
              "         [ 0.0943, -0.3156,  0.7850, -0.8699, -1.6525],\n",
              "         [ 0.6455, -0.3313, -1.0390,  0.9112,  1.2984]]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see a single Head perform self-attention\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)"
      ],
      "metadata": {
        "id": "HbzrB4dguxZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = key(x)   # (B, T, 16)\n",
        "k[:2,:,:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss5NOZFPu7k-",
        "outputId": "523eae90-4279-43bd-88ca-ca75c998235f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1196, -0.3013,  0.3629,  1.1771,  1.1385],\n",
              "         [-0.5423, -0.5558, -0.0761,  1.2929,  0.8653],\n",
              "         [-0.3736, -0.4678, -0.2156, -0.8034, -0.3715],\n",
              "         [-0.3146,  0.0845, -0.1235, -0.7058, -0.1802],\n",
              "         [ 0.0239,  0.0998, -0.1871, -0.0860, -0.4881],\n",
              "         [-0.2362, -0.7873, -0.3802,  0.5815, -0.3722],\n",
              "         [-0.7941, -0.1660, -0.2810, -0.1021, -0.7352],\n",
              "         [ 0.1651, -0.1599, -0.5717, -0.3957,  0.3930]],\n",
              "\n",
              "        [[-0.1698, -1.5875, -0.9185,  0.0663, -1.1497],\n",
              "         [-0.1144, -0.3531, -0.1843,  0.5200, -0.6060],\n",
              "         [-0.6351, -1.0090,  0.4485,  0.2610,  0.3095],\n",
              "         [ 0.0712,  0.5713,  0.6227,  0.2422,  1.1163],\n",
              "         [-0.0329,  0.5380,  0.0509,  1.1635, -0.1320],\n",
              "         [-0.1540,  0.6426, -0.1227,  0.4075,  0.0728],\n",
              "         [ 0.7557, -0.1168, -0.7970,  0.0162,  0.8680],\n",
              "         [ 0.1957,  0.1531, -0.2639, -0.9068, -0.8997]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = query(x) # (B, T, 16)\n",
        "q[:1, :1, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33VcOUV5vERp",
        "outputId": "a7e75712-59b7-4cf8-9177-fd6ed0c317b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.6567,  0.0283,  0.0094, -0.6995, -0.3604,  0.8376, -0.4446,\n",
              "           0.1228,  0.6276, -0.6222,  0.3483,  0.2411,  0.5409, -0.2605,\n",
              "           0.3612, -0.0436]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[:1, :1 , :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgvOppPExFpy",
        "outputId": "657359fa-291d-4f59-e4dd-a58bbb15b37a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1196, -0.3013,  0.3629,  1.1771,  1.1385, -0.2554,  0.1454,\n",
              "          -0.2944, -0.7020, -1.0308,  0.7436, -0.8098, -0.6669,  0.0912,\n",
              "          -0.0061,  0.1983]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k[:1, :1 , :].transpose(-2,-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dveP0VsAw8HK",
        "outputId": "802755f7-2646-482f-f22c-cd89bcb0fe77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.1196],\n",
              "         [-0.3013],\n",
              "         [ 0.3629],\n",
              "         [ 1.1771],\n",
              "         [ 1.1385],\n",
              "         [-0.2554],\n",
              "         [ 0.1454],\n",
              "         [-0.2944],\n",
              "         [-0.7020],\n",
              "         [-1.0308],\n",
              "         [ 0.7436],\n",
              "         [-0.8098],\n",
              "         [-0.6669],\n",
              "         [ 0.0912],\n",
              "         [-0.0061],\n",
              "         [ 0.1983]]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei =  q @ k.transpose(-2, -1) # (B, T, 16) @ (B, 16, T) ---> (B, T, T)\n",
        "wei[:2,:,:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdNW0DVDv3yr",
        "outputId": "bdc20956-a52f-4def-c7c9-2a8a0cef0166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.7629, -1.3011,  0.5652,  2.1616, -1.0674],\n",
              "         [-3.3334, -1.6556,  0.1040,  3.3782, -2.1825],\n",
              "         [-1.0226, -1.2606,  0.0762, -0.3813, -0.9843],\n",
              "         [ 0.7836, -0.8014, -0.3368, -0.8496, -0.5602],\n",
              "         [-1.2566,  0.0187, -0.7880, -1.3204,  2.0363],\n",
              "         [-0.3126,  2.4152, -0.1106, -0.9931,  3.3449],\n",
              "         [ 1.0876,  1.9652, -0.2621, -0.3158,  0.6091],\n",
              "         [-1.8044, -0.4126, -0.8306,  0.5899, -0.7987]],\n",
              "\n",
              "        [[-0.7353, -1.7807,  1.0745, -0.2743,  1.6347],\n",
              "         [-3.0892, -1.4943, -0.2617,  2.2760, -0.2436],\n",
              "         [-0.5021, -2.0745,  0.5379, -0.4049,  0.8329],\n",
              "         [ 1.3810, -0.1471,  1.2181, -0.2227, -1.8247],\n",
              "         [-2.3568, -0.4617, -0.8820,  2.3700,  0.6783],\n",
              "         [-0.9243, -0.6235, -1.3938,  1.3336, -0.0090],\n",
              "         [-0.6552,  1.0991, -2.1399,  0.9647,  0.9946],\n",
              "         [ 1.5463, -0.4944, -0.0142, -0.9743,  1.3779]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "tril"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyf6AuUawF3e",
        "outputId": "0e3d839f-77a2-490a-fa65-543002e5f5b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "wei[:1, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ObOWOKNzoo0",
        "outputId": "8303194c-8f6a-45d0-c6ef-3372ef829460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
              "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
              "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
              "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]]],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = value(x)\n",
        "v[:1, :, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDf4zM4QzsLN",
        "outputId": "b58ffe67-57f2-4bd0-b78f-8afbde5989b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007,\n",
              "          -0.5239, -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,\n",
              "           0.2862,  0.5710],\n",
              "         [ 0.8321, -0.8144, -0.3242,  0.5191, -0.1252, -0.4898, -0.5287,\n",
              "          -0.0314,  0.1072,  0.8269,  0.8132, -0.0271,  0.4775,  0.4980,\n",
              "          -0.1377,  1.4025],\n",
              "         [ 0.6035, -0.2500, -0.6159,  0.4068,  0.3328, -0.3910,  0.1312,\n",
              "           0.2172, -0.1299, -0.8828,  0.1724,  0.4652, -0.4271, -0.0768,\n",
              "          -0.2852,  1.3875],\n",
              "         [ 0.6657, -0.7096, -0.6099,  0.4348,  0.8975, -0.9298,  0.0683,\n",
              "           0.1863,  0.5400,  0.2427, -0.6923,  0.4977,  0.4850,  0.6608,\n",
              "           0.8767,  0.0746],\n",
              "         [ 0.1536,  1.0439,  0.8457,  0.2388,  0.3005,  1.0516,  0.7637,\n",
              "           0.4517, -0.7426, -1.4395, -0.4941, -0.3709, -1.1819,  0.1000,\n",
              "          -0.1806,  0.5129],\n",
              "         [-0.8920,  0.0578, -0.3350,  0.8477,  0.3876,  0.1664, -0.4587,\n",
              "          -0.5974,  0.4961,  0.6548,  0.0548,  0.9468,  0.4511,  0.1200,\n",
              "           1.0573, -0.2257],\n",
              "         [-0.4849,  0.1655, -0.2221, -0.1345, -0.0864, -0.6628, -0.0936,\n",
              "           0.1050, -0.2612,  0.1854,  0.3171, -0.1393,  0.5486, -0.4086,\n",
              "          -0.3851,  0.7106],\n",
              "         [ 0.2042,  0.3772, -1.1255,  0.3995,  0.1489,  0.3590, -0.1791,\n",
              "           1.3732,  0.1588, -0.2320,  0.1651,  0.7604,  0.3521, -1.0864,\n",
              "          -0.7939, -0.3025]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = wei @ v\n",
        "print(wei.shape)\n",
        "print(v.shape)\n",
        "out[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKnpINiP0EZt",
        "outputId": "107dc63c-a210-400d-af81-73e2ae83dd62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8, 8])\n",
            "torch.Size([4, 8, 16])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1571,  0.8801,  0.1615, -0.7824, -0.1429,  0.7468,  0.1007,\n",
              "          -0.5239, -0.8873,  0.1907,  0.1762, -0.5943, -0.4812, -0.4860,\n",
              "           0.2862,  0.5710],\n",
              "         [ 0.6764, -0.5477, -0.2478,  0.3143, -0.1280, -0.2952, -0.4296,\n",
              "          -0.1089, -0.0493,  0.7268,  0.7130, -0.1164,  0.3266,  0.3431,\n",
              "          -0.0710,  1.2716],\n",
              "         [ 0.4823, -0.1069, -0.4055,  0.1770,  0.1581, -0.1697,  0.0162,\n",
              "           0.0215, -0.2490, -0.3773,  0.2787,  0.1629, -0.2895, -0.0676,\n",
              "          -0.1416,  1.2194],\n",
              "         [ 0.1971,  0.2856, -0.1303, -0.2655,  0.0668,  0.1954,  0.0281,\n",
              "          -0.2451, -0.4647,  0.0693,  0.1528, -0.2032, -0.2479, -0.1621,\n",
              "           0.1947,  0.7678],\n",
              "         [ 0.2510,  0.7346,  0.5939,  0.2516,  0.2606,  0.7582,  0.5595,\n",
              "           0.3539, -0.5934, -1.0807, -0.3111, -0.2781, -0.9054,  0.1318,\n",
              "          -0.1382,  0.6371],\n",
              "         [ 0.3428,  0.4960,  0.4725,  0.3028,  0.1844,  0.5814,  0.3824,\n",
              "           0.2952, -0.4897, -0.7705, -0.1172, -0.2541, -0.6892,  0.1979,\n",
              "          -0.1513,  0.7666],\n",
              "         [ 0.1866, -0.0964, -0.1430,  0.3059,  0.0834, -0.0069, -0.2047,\n",
              "          -0.1535, -0.0762,  0.3269,  0.3090,  0.0766,  0.0992,  0.1656,\n",
              "           0.1975,  0.7625],\n",
              "         [ 0.1301, -0.0328, -0.4965,  0.2865,  0.2704, -0.2636, -0.0738,\n",
              "           0.3786,  0.0746,  0.0338,  0.0147,  0.3194,  0.2993, -0.1653,\n",
              "          -0.0386,  0.3375]]], grad_fn=<SliceBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # how many independent sequences will we process in parallel?\n",
        "block_size = 64 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4\n",
        "n_layer = 4\n",
        "dropout = 0.2"
      ],
      "metadata": {
        "id": "7imSaO7_xUBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ndjcHqWgx-A_",
        "outputId": "a1e9f2ac-8135-443b-81e0-cedc7eb1c194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "\n",
        "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "JZKGDgRgyb9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ],
      "metadata": {
        "id": "WibCzJ4tyzYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Head(nn.Module):\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C)\n",
        "        q = self.query(x) # (B,T,C)\n",
        "\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out"
      ],
      "metadata": {
        "id": "Yp7DVjJ5zA1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "8hCYp7B4zM1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedFoward(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "metadata": {
        "id": "0lzINqT8zQCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "x0oGTYwBzZ5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "\n",
        "            logits, loss = self(idx_cond)\n",
        "\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "MK-x-SZJzd1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel()\n",
        "m = model.to(device)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=2000)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLmaw1J7zkfe",
        "outputId": "508ddd3a-4a67-4596-cec4-0e80a9feea4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.211777 M parameters\n",
            "step 0: train loss 4.3387, val loss 4.3485\n",
            "step 100: train loss 2.6136, val loss 2.6146\n",
            "step 200: train loss 2.4867, val loss 2.4921\n",
            "step 300: train loss 2.3950, val loss 2.3991\n",
            "step 400: train loss 2.3156, val loss 2.3236\n",
            "step 500: train loss 2.2504, val loss 2.2679\n",
            "step 600: train loss 2.1927, val loss 2.2158\n",
            "step 700: train loss 2.1424, val loss 2.1659\n",
            "step 800: train loss 2.0993, val loss 2.1317\n",
            "step 900: train loss 2.0542, val loss 2.0991\n",
            "step 1000: train loss 2.0156, val loss 2.0730\n",
            "step 1100: train loss 1.9740, val loss 2.0360\n",
            "step 1200: train loss 1.9364, val loss 2.0128\n",
            "step 1300: train loss 1.9063, val loss 1.9898\n",
            "step 1400: train loss 1.8759, val loss 1.9575\n",
            "step 1500: train loss 1.8500, val loss 1.9488\n",
            "step 1600: train loss 1.8251, val loss 1.9416\n",
            "step 1700: train loss 1.8070, val loss 1.9300\n",
            "step 1800: train loss 1.7870, val loss 1.9231\n",
            "step 1900: train loss 1.7707, val loss 1.9033\n",
            "step 2000: train loss 1.7440, val loss 1.8887\n",
            "step 2100: train loss 1.7364, val loss 1.8778\n",
            "step 2200: train loss 1.7210, val loss 1.8662\n",
            "step 2300: train loss 1.7103, val loss 1.8667\n",
            "step 2400: train loss 1.6920, val loss 1.8478\n",
            "step 2500: train loss 1.6944, val loss 1.8602\n",
            "step 2600: train loss 1.6704, val loss 1.8326\n",
            "step 2700: train loss 1.6556, val loss 1.8254\n",
            "step 2800: train loss 1.6436, val loss 1.8156\n",
            "step 2900: train loss 1.6441, val loss 1.8127\n",
            "step 3000: train loss 1.6341, val loss 1.8030\n",
            "step 3100: train loss 1.6165, val loss 1.7965\n",
            "step 3200: train loss 1.6180, val loss 1.7891\n",
            "step 3300: train loss 1.6069, val loss 1.7731\n",
            "step 3400: train loss 1.6088, val loss 1.7849\n",
            "step 3500: train loss 1.5937, val loss 1.7639\n",
            "step 3600: train loss 1.5900, val loss 1.7697\n",
            "step 3700: train loss 1.5837, val loss 1.7609\n",
            "step 3800: train loss 1.5821, val loss 1.7605\n",
            "step 3900: train loss 1.5827, val loss 1.7531\n",
            "step 4000: train loss 1.5703, val loss 1.7563\n",
            "step 4100: train loss 1.5697, val loss 1.7436\n",
            "step 4200: train loss 1.5602, val loss 1.7494\n",
            "step 4300: train loss 1.5558, val loss 1.7379\n",
            "step 4400: train loss 1.5499, val loss 1.7243\n",
            "step 4500: train loss 1.5436, val loss 1.7235\n",
            "step 4600: train loss 1.5449, val loss 1.7332\n",
            "step 4700: train loss 1.5482, val loss 1.7325\n",
            "step 4800: train loss 1.5315, val loss 1.7261\n",
            "step 4900: train loss 1.5330, val loss 1.7263\n",
            "step 4999: train loss 1.5273, val loss 1.7211\n",
            "\n",
            "\n",
            "YORK:\n",
            "I bridchwing, is to be made to be extain,\n",
            "That thy dagain\n",
            "My art that us hath bury. Citizea endriced you,\n",
            "Doth on her heavens, to time come my falight,\n",
            "Which entend, will is the overt, and the now on traitor likind me up\n",
            "the merdering: therefiselly, yet love.\n",
            "I may persigues, to the oddied against,\n",
            "Not her evil so' thine suit high\n",
            "To end poor of his butter danks,\n",
            "They so;\n",
            "And he must with ale oftenceful. For I am.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Saday Warwick, shoulin cour acrace\n",
            "Hird to changed very time on, by are thou contract?\n",
            "Is not hersel--'times the men.\n",
            "\n",
            "CORIOLANUS:\n",
            "Where not usibon, with confrioys shoutch; lord\n",
            "Is as we lope.\n",
            "\n",
            "SOMEY:\n",
            "Indeed me over a main?\n",
            "\n",
            "LADY:\n",
            "Ay, my by some so upon thou fend talk:\n",
            "Whither she sun her, is desire.\n",
            "\n",
            "Fort:\n",
            "Nor the beards against uncesta soul.\n",
            "\n",
            "Cluclord:\n",
            "Comes welcome this and the I subried.\n",
            "\n",
            "KING HENRY Genourn thy your time of time\n",
            "The show the summorely other is be than the cust\n",
            "Of Blawle made to him, there accuration it\n",
            "on the gaven Glood conscue?\n",
            "\n",
            "Firse:\n",
            "\n",
            "ANGELO:\n",
            "I, I hus not whence nurce i' this, not take all not weep she\n",
            "To my be rest mines and ends\n",
            "Singin in-soneit this falst did child frien\n",
            "Her hath aI have a caniet to makes come and keep,\n",
            "To men, there's woeing breature on have eaven.\n",
            "\n",
            "GLORIO:\n",
            "Go had will tell too uslables.\n",
            "\n",
            "DUKE OF NORWANDjEY:\n",
            "A friend, Maughhh, are burn she love is caper'd,\n",
            "Prinkentury the now cherfury.\n",
            "\n",
            "HENRY YORK:\n",
            "O love you, must that swen them the depire\n",
            "Gom Twiter, sy, delel! Here so, I am will raw oldier\n",
            "And by griorns thou out,---while every.\n",
            "\n",
            "Thine of a-lates coriun!\n",
            "\n",
            "BENVALY:\n",
            "Never, when sir. Frover, shall be my hath, are patry things?\n",
            "\n",
            "PORWANUS:\n",
            "Through. The live should, that been\n",
            "from thine as though, matura.\n",
            "\n",
            "Firself:\n",
            "Not, there wife it me father, made courcils,\n",
            "And the livoury talked at the sent.\n",
            "\n",
            "HENRY BOLILIZABETH:\n",
            "You their eveliant, shook to proop,\n",
            "Brace will know-looken a would promind. I was not the fair,\n",
            "Than you do, Julio, pardinitnessions men's from thee suppection's\n",
            "In depair'd, \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sixb04eM0bOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}